{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a00b3aed",
   "metadata": {},
   "source": [
    "# OpenVINO Training Extension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9548bf78",
   "metadata": {},
   "source": [
    "## Import everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717eca7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from ote_sdk.configuration.helper import create as create_parameters_from_parameters_schema\n",
    "from ote_sdk.entities.inference_parameters import InferenceParameters\n",
    "from ote_sdk.entities.label_schema import LabelSchemaEntity\n",
    "from ote_sdk.entities.model import ModelEntity, ModelOptimizationType\n",
    "from ote_sdk.entities.resultset import ResultSetEntity\n",
    "from ote_sdk.entities.subset import Subset\n",
    "from ote_sdk.entities.task_environment import TaskEnvironment\n",
    "from ote_sdk.entities.optimization_parameters import OptimizationParameters\n",
    "from ote_sdk.usecases.adapters.model_adapter import ModelAdapter\n",
    "from ote_sdk.usecases.tasks.interfaces.export_interface import ExportType\n",
    "from ote_sdk.usecases.tasks.interfaces.optimization_interface import OptimizationType\n",
    "\n",
    "from ote_cli.datasets import get_dataset_class\n",
    "from ote_cli.registry import Registry\n",
    "from ote_cli.utils.importing import get_impl_class\n",
    "from ote_cli.utils.io import read_binary, save_model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ad843f",
   "metadata": {},
   "source": [
    "## Register templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c86d79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "templates_dir = '../external'\n",
    "registry = Registry(templates_dir)\n",
    "print(registry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a64b5",
   "metadata": {},
   "source": [
    "## Load model template and its hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f08de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_template = registry.get('Custom_Object_Detection_Gen3_ATSS')\n",
    "hyper_parameters = model_template.hyper_parameters.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fbfd14",
   "metadata": {},
   "source": [
    "## Get dataset instantiated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b43d83e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Dataset = get_dataset_class(model_template.task_type)\n",
    "\n",
    "dataset = Dataset(\n",
    "    train_subset={'ann_file': '../data/airport/annotation_faces_train.json',\n",
    "                  'data_root': '../data/airport/'},\n",
    "    val_subset={'ann_file': '../data/airport/annotation_faces_train.json',\n",
    "                'data_root': '../data/airport'}\n",
    ")\n",
    "labels_schema = LabelSchemaEntity.from_labels(dataset.get_labels())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c260bb",
   "metadata": {},
   "source": [
    "## Have a look at existing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c340c7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hyper_parameters = create_parameters_from_parameters_schema(hyper_parameters)\n",
    "\n",
    "for p in hyper_parameters.learning_parameters.parameters:\n",
    "    print(f'{p}: {getattr(hyper_parameters.learning_parameters, p)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c28d21",
   "metadata": {},
   "source": [
    "## Tweak parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c791af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters.learning_parameters.batch_size = 8\n",
    "hyper_parameters.learning_parameters.num_iters = 15\n",
    "\n",
    "for p in hyper_parameters.learning_parameters.parameters:\n",
    "    print(f'{p}: {getattr(hyper_parameters.learning_parameters, p)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af16f4a",
   "metadata": {},
   "source": [
    "## Create Task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94afc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "Task = get_impl_class(model_template.entrypoints.base)\n",
    "\n",
    "environment = TaskEnvironment(\n",
    "    model=None,\n",
    "    hyper_parameters=hyper_parameters,\n",
    "    label_schema=labels_schema,\n",
    "    model_template=model_template)\n",
    "        \n",
    "task = Task(task_environment=environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b02f5fe",
   "metadata": {},
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9896ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch_model = ModelEntity(\n",
    "    dataset,\n",
    "    environment.get_model_configuration(),\n",
    ")\n",
    "\n",
    "task.train(dataset, torch_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c235b6a8",
   "metadata": {},
   "source": [
    "## Evaluate quality metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb7ffb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validation_dataset = dataset.get_subset(Subset.VALIDATION)\n",
    "predicted_validation_dataset = task.infer(\n",
    "    validation_dataset.with_empty_annotations(),\n",
    "    InferenceParameters(is_evaluation=True))\n",
    "\n",
    "resultset = ResultSetEntity(\n",
    "    model=torch_model,\n",
    "    ground_truth_dataset=validation_dataset,\n",
    "    prediction_dataset=predicted_validation_dataset,\n",
    ")\n",
    "task.evaluate(resultset)\n",
    "print(resultset.performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301445d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_data(torch_model, \"./torch_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b4d686",
   "metadata": {},
   "source": [
    "## OpenVINO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4784e973",
   "metadata": {},
   "source": [
    "### Export PyTorch model to OpenVINO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d5f811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exported_model = ModelEntity(\n",
    "    dataset,\n",
    "    environment.get_model_configuration(),\n",
    ")\n",
    "task.export(ExportType.OPENVINO, exported_model)\n",
    "save_model_data(exported_model, \"./exported_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7327b120",
   "metadata": {},
   "source": [
    "### Evaluate the exported model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b01094",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "environment.model = exported_model\n",
    "ov_task = get_impl_class(model_template.entrypoints.openvino)(environment)\n",
    "predicted_validation_dataset = ov_task.infer(\n",
    "    validation_dataset.with_empty_annotations(),\n",
    "    InferenceParameters(is_evaluation=True))\n",
    "resultset = ResultSetEntity(\n",
    "    model=exported_model,\n",
    "    ground_truth_dataset=validation_dataset,\n",
    "    prediction_dataset=predicted_validation_dataset,\n",
    ")\n",
    "ov_task.evaluate(resultset)\n",
    "print(resultset.performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6469c001",
   "metadata": {},
   "outputs": [],
   "source": [
    "!benchmark_app -m ./exported_model/openvino.xml  -i ../data/airport/val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf97a63",
   "metadata": {},
   "source": [
    "## Optimize OpenVINO with POT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b35e284",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.model = exported_model\n",
    "pot_model = ModelEntity(\n",
    "    dataset,\n",
    "    environment.get_model_configuration(),\n",
    ")\n",
    "\n",
    "ov_task.optimize(\n",
    "    OptimizationType.POT,\n",
    "    dataset,\n",
    "    pot_model,\n",
    "    OptimizationParameters(),\n",
    ")\n",
    "\n",
    "save_model_data(pot_model, \"./pot_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ce00de",
   "metadata": {},
   "source": [
    "### Evaluate OpenVINO POT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba6507",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.model = pot_model\n",
    "ov_task = get_impl_class(model_template.entrypoints.openvino)(environment)\n",
    "predicted_validation_dataset = ov_task.infer(\n",
    "    validation_dataset.with_empty_annotations(),\n",
    "    InferenceParameters(is_evaluation=True))\n",
    "resultset = ResultSetEntity(\n",
    "    model=pot_model,\n",
    "    ground_truth_dataset=validation_dataset,\n",
    "    prediction_dataset=predicted_validation_dataset,\n",
    ")\n",
    "ov_task.evaluate(resultset)\n",
    "print(resultset.performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae868bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!benchmark_app -m ./pot_model/openvino.xml  -i ../data/airport/val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e54cb5",
   "metadata": {},
   "source": [
    "## NNCF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733a2c86",
   "metadata": {},
   "source": [
    "### Compress PyTorch model with NNCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9c7b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.model = torch_model\n",
    "nncf_model = ModelEntity(dataset, environment.get_model_configuration())\n",
    "nncf_task = get_impl_class(model_template.entrypoints.nncf)(environment)\n",
    "nncf_task.optimize(\n",
    "        OptimizationType.NNCF,\n",
    "        dataset,\n",
    "        nncf_model,\n",
    "        OptimizationParameters(),\n",
    "    )\n",
    "save_model_data(nncf_model, \"./nncf_torch_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ba0079",
   "metadata": {},
   "source": [
    "### Evaluate the compressed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740be636",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_validation_dataset = nncf_task.infer(\n",
    "    validation_dataset.with_empty_annotations(),\n",
    "    InferenceParameters(is_evaluation=True))\n",
    "resultset = ResultSetEntity(\n",
    "    model=nncf_model,\n",
    "    ground_truth_dataset=validation_dataset,\n",
    "    prediction_dataset=predicted_validation_dataset,\n",
    ")\n",
    "nncf_task.evaluate(resultset)\n",
    "print(resultset.performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8d1fac",
   "metadata": {},
   "source": [
    "### Export NNCF PyTorch to OpenVINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3989985",
   "metadata": {},
   "outputs": [],
   "source": [
    "nncf_exported_model = ModelEntity(None, environment.get_model_configuration())\n",
    "nncf_task.export(ExportType.OPENVINO, nncf_exported_model)\n",
    "save_model_data(nncf_exported_model, \"./nncf_exported_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b899a63",
   "metadata": {},
   "source": [
    "### Evaluate NNCF OpenVINO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749846b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.model = nncf_exported_model\n",
    "ov_task = get_impl_class(model_template.entrypoints.openvino)(environment)\n",
    "predicted_validation_dataset = ov_task.infer(\n",
    "    validation_dataset.with_empty_annotations(),\n",
    "    InferenceParameters(is_evaluation=True))\n",
    "resultset = ResultSetEntity(\n",
    "    model=nncf_exported_model,\n",
    "    ground_truth_dataset=validation_dataset,\n",
    "    prediction_dataset=predicted_validation_dataset,\n",
    ")\n",
    "ov_task.evaluate(resultset)\n",
    "print(resultset.performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e810af6c",
   "metadata": {},
   "source": [
    "## Draw bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bae4d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "import PIL\n",
    "\n",
    "for predictions, item in zip(predicted_validation_dataset, validation_dataset.with_empty_annotations()):\n",
    "    image = item.numpy.astype(np.uint8)\n",
    "    for box in predictions.annotation_scene.shapes:\n",
    "        x1 = int(box.x1 * image.shape[1])\n",
    "        x2 = int(box.x2 * image.shape[1])\n",
    "        y1 = int(box.y1 * image.shape[0])\n",
    "        y2 = int(box.y2 * image.shape[0])\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 0, 255), 3)  \n",
    "    IPython.display.display(PIL.Image.fromarray(image))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e0b5d28c3cfa9791611f1bb5182312c607031331c46d3b829f8d49708cc49691"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
