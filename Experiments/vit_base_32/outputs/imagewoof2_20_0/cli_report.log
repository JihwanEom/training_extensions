

 ██████╗     ████████╗    ██╗  ██╗
██╔═══██╗    ╚══██╔══╝    ╚██╗██╔╝
██║   ██║       ██║        ╚███╔╝
██║   ██║       ██║        ██╔██╗
╚██████╔╝       ██║       ██╔╝ ██╗
 ╚═════╝        ╚═╝       ╚═╝  ╚═╝

------------------------------------------------------------

Current path: /home/jeom/ws/otx-vit/Experiments/vit_base_32
sys.argv: ['otx train', '--output', 'outputs/imagewoof2_20_0', '--data', '../../data/imagewoof2_20_0.yaml', 'params', '--learning_parameters.num_iters', '90', '--learning_parameters.batch_size', '8', '--learning_parameters.learning_rate', '0.001']
OTX: 1.2.0rc0
------------------------------------------------------------

Running Environments

------------------------------------------------------------
	sys.platform: linux
	Python: 3.10.10 (main, Mar 21 2023, 18:45:11) [GCC 11.2.0]
	CUDA available: True
	GPU 0,1: NVIDIA GeForce RTX 3090
	CUDA_HOME: /usr/local/cuda
	NVCC: Cuda compilation tools, release 11.1, V11.1.74
	GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
	PyTorch: 1.13.1+cu117
	TorchVision: 0.14.1+cu117
	OpenCV: 4.7.0
	MMCV: 1.7.0
	MMCV Compiler: GCC 9.4
	MMCV CUDA Compiler: 11.1
------------------------------------------------------------

Template Information

------------------------------------------------------------
	model_template_id: 'Custom_Image_Classification_EfficinetNet-B0'
	model_template_path: 'template.yaml'
	name: 'EfficientNet-B0'
	task_family: <TaskFamily.VISION: 1>
	task_type: CLASSIFICATION
	instantiation: <InstantiationType.CLASS: 2>
	summary: 'Class-Incremental Image Classification for EfficientNet-B0'
	framework: 'OTXClassification v1.2.3'
	max_nodes: 1
	application: None
	dependencies: []
	initial_weights: None
	training_targets: [<TargetDevice.GPU: 3>, <TargetDevice.CPU: 2>]
	inference_targets: []
	dataset_requirements: DatasetRequirements(classes=None)
	model_optimization_methods: []
	hyper_parameters: HyperParameterData(base_path='./configuration.yaml',
                   parameter_overrides={'algo_backend': {'train_type': {'default_value': 'Incremental'}},
                                        'learning_parameters': {'batch_size': {'auto_hpo_state': 'POSSIBLE',
                                                                               'default_value': 64},
                                                                'learning_rate': {'auto_hpo_state': 'POSSIBLE',
                                                                                  'default_value': 0.0049},
                                                                'learning_rate_warmup_iters': {'default_value': 0},
                                                                'num_iters': {'default_value': 3}},
                                        'nncf_optimization': {'enable_pruning': {'default_value': False},
                                                              'enable_quantization': {'default_value': True},
                                                              'maximal_accuracy_degradation': {'default_value': 1.0},
                                                              'pruning_supported': {'default_value': True}}})
	is_trainable: True
	capabilities: ['compute_representations']
	grpc_address: None
	entrypoints: EntryPoints(base='otx.algorithms.classification.adapters.mmcls.task.MMClassificationTask',
            openvino='otx.algorithms.classification.adapters.openvino.task.ClassificationOpenVINOTask',
            nncf='otx.algorithms.classification.adapters.mmcls.nncf.task.ClassificationNNCFTask')
	base_model_path: ''
	exportable_code_paths: ExportableCodePaths(default=None, openvino=None)
	task_type_sort_priority: -1
	gigaflops: 0.81
	size: 4.09
	hpo: None
------------------------------------------------------------

Dataset Information

------------------------------------------------------------
train_subset:
	data_root: /home/jeom/ws/data/subset/imagewoof2_20_0/train
val_subset:
	data_root: /home/jeom/ws/data/imagewoof2/val
------------------------------------------------------------

Configurations

------------------------------------------------------------
url: 'https://download.openmmlab.com/mmclassification/v0/vit/pretrain/vit-base-p32_3rdparty_pt-64xb64_in1k-224_20210928-eee25dd4.pth'
model: {'backbone': {'arch': 'base',
              'drop_path_rate': 0.0,
              'drop_rate': 0.1,
              'final_norm': True,
              'img_size': 224,
              'in_channels': 3,
              'init_cfg': {'checkpoint': 'https://download.openmmlab.com/mmclassification/v0/vit/pretrain/vit-base-p32_3rdparty_pt-64xb64_in1k-224_20210928-eee25dd4.pth',
                           'prefix': 'backbone',
                           'type': 'Pretrained'},
              'interpolate_mode': 'bicubic',
              'layer_cfgs': {},
              'norm_cfg': {'eps': 1e-06, 'type': 'LN'},
              'out_indices': -1,
              'output_cls_token': True,
              'patch_cfg': {},
              'patch_size': 32,
              'qkv_bias': True,
              'type': 'mmcls.VisionTransformer',
              'with_cls_token': True},
 'head': {'in_channels': 768,
          'loss': {'loss_weight': 1.0, 'type': 'CrossEntropyLoss'},
          'num_classes': 10,
          'topk': (1, 5),
          'type': 'VisionTransformerClsHead'},
 'hierarchical': False,
 'multilabel': False,
 'neck': None,
 'pretrained': None,
 'type': 'SAMImageClassifier'}
dist_params: {'backend': 'nccl', 'linear_scale_lr': True}
cudnn_benchmark: True
seed: 0
deterministic: True
hparams: {'dummy': 0}
task_adapt: {'op': 'REPLACE', 'type': 'mpa'}
log_level: 'INFO'
optimizer: {'lr': 0.001, 'momentum': 0.9, 'type': 'SGD', 'weight_decay': 0.0005}
optimizer_config: {'distributed': False,
 'grad_clip': None,
 'loss_scale': 512.0,
 'type': 'Fp16SAMOptimizerHook'}
runner: {'max_epochs': 90, 'type': 'EpochRunnerWithCancel'}
workflow: [('train', 1)]
lr_config: {'min_lr_ratio': 0.0001,
 'policy': 'CosineAnnealing',
 'warmup': None,
 'warmup_iters': 0}
evaluation: {'metric': ['accuracy', 'class_accuracy']}
resume_from: None
checkpoint_config: {'interval': 1, 'max_keep_ckpts': 1, 'type': 'CheckpointHookWithValResults'}
custom_imports: {'allow_failed_imports': False, 'imports': ['mmcls.models']}
domain: <Domain.CLASSIFICATION: 2>
data: {'test': {'domain': <Domain.CLASSIFICATION: 2>,
          'empty_label': None,
          'labels': [LabelEntity(0, name=n02086240, hotkey=, domain=CLASSIFICATION, color=Color(red=107, green=21, blue=167, alpha=255), is_anomalous=False),
                     LabelEntity(1, name=n02087394, hotkey=, domain=CLASSIFICATION, color=Color(red=76, green=172, blue=179, alpha=255), is_anomalous=False),
                     LabelEntity(2, name=n02088364, hotkey=, domain=CLASSIFICATION, color=Color(red=255, green=42, blue=28, alpha=255), is_anomalous=False),
                     LabelEntity(3, name=n02089973, hotkey=, domain=CLASSIFICATION, color=Color(red=92, green=21, blue=18, alpha=255), is_anomalous=False),
                     LabelEntity(4, name=n02093754, hotkey=, domain=CLASSIFICATION, color=Color(red=9, green=41, blue=34, alpha=255), is_anomalous=False),
                     LabelEntity(5, name=n02096294, hotkey=, domain=CLASSIFICATION, color=Color(red=171, green=173, blue=145, alpha=255), is_anomalous=False),
                     LabelEntity(6, name=n02099601, hotkey=, domain=CLASSIFICATION, color=Color(red=55, green=209, blue=141, alpha=255), is_anomalous=False),
                     LabelEntity(7, name=n02105641, hotkey=, domain=CLASSIFICATION, color=Color(red=125, green=60, blue=27, alpha=255), is_anomalous=False),
                     LabelEntity(8, name=n02111889, hotkey=, domain=CLASSIFICATION, color=Color(red=149, green=182, blue=114, alpha=255), is_anomalous=False),
                     LabelEntity(9, name=n02115641, hotkey=, domain=CLASSIFICATION, color=Color(red=57, green=252, blue=134, alpha=255), is_anomalous=False)],
          'pipeline': [{'size': 224, 'type': 'Resize'},
                       {'mean': [123.675, 116.28, 103.53],
                        'std': [58.395, 57.12, 57.375],
                        'to_rgb': False,
                        'type': 'Normalize'},
                       {'keys': ['img'], 'type': 'ImageToTensor'},
                       {'keys': ['img'], 'type': 'Collect'}],
          'test_mode': True,
          'type': 'OTXClsDataset'},
 'test_dataloader': {'samples_per_gpu': 8, 'workers_per_gpu': 2},
 'train': {'domain': <Domain.CLASSIFICATION: 2>,
           'empty_label': None,
           'labels': [LabelEntity(0, name=n02086240, hotkey=, domain=CLASSIFICATION, color=Color(red=107, green=21, blue=167, alpha=255), is_anomalous=False),
                      LabelEntity(1, name=n02087394, hotkey=, domain=CLASSIFICATION, color=Color(red=76, green=172, blue=179, alpha=255), is_anomalous=False),
                      LabelEntity(2, name=n02088364, hotkey=, domain=CLASSIFICATION, color=Color(red=255, green=42, blue=28, alpha=255), is_anomalous=False),
                      LabelEntity(3, name=n02089973, hotkey=, domain=CLASSIFICATION, color=Color(red=92, green=21, blue=18, alpha=255), is_anomalous=False),
                      LabelEntity(4, name=n02093754, hotkey=, domain=CLASSIFICATION, color=Color(red=9, green=41, blue=34, alpha=255), is_anomalous=False),
                      LabelEntity(5, name=n02096294, hotkey=, domain=CLASSIFICATION, color=Color(red=171, green=173, blue=145, alpha=255), is_anomalous=False),
                      LabelEntity(6, name=n02099601, hotkey=, domain=CLASSIFICATION, color=Color(red=55, green=209, blue=141, alpha=255), is_anomalous=False),
                      LabelEntity(7, name=n02105641, hotkey=, domain=CLASSIFICATION, color=Color(red=125, green=60, blue=27, alpha=255), is_anomalous=False),
                      LabelEntity(8, name=n02111889, hotkey=, domain=CLASSIFICATION, color=Color(red=149, green=182, blue=114, alpha=255), is_anomalous=False),
                      LabelEntity(9, name=n02115641, hotkey=, domain=CLASSIFICATION, color=Color(red=57, green=252, blue=134, alpha=255), is_anomalous=False)],
           'new_classes': ['n02086240',
                           'n02087394',
                           'n02088364',
                           'n02089973',
                           'n02093754',
                           'n02096294',
                           'n02099601',
                           'n02105641',
                           'n02111889',
                           'n02115641'],
           'pipeline': [{'size': 224, 'type': 'Resize'},
                        {'direction': 'horizontal',
                         'flip_prob': 0.5,
                         'type': 'RandomFlip'},
                        {'config_str': 'augmix-m5-w3', 'type': 'AugMixAugment'},
                        {'angle': (-10, 10), 'p': 0.35, 'type': 'RandomRotate'},
                        {'keys': ['img'], 'type': 'PILImageToNDArray'},
                        {'mean': [123.675, 116.28, 103.53],
                         'std': [58.395, 57.12, 57.375],
                         'to_rgb': False,
                         'type': 'Normalize'},
                        {'keys': ['img'], 'type': 'ImageToTensor'},
                        {'keys': ['gt_label'], 'type': 'ToTensor'},
                        {'keys': ['img', 'gt_label'],
                         'meta_keys': {'filename',
                                       'flip',
                                       'flip_direction',
                                       'ignored_labels',
                                       'img_norm_cfg',
                                       'img_shape',
                                       'ori_filename',
                                       'ori_shape',
                                       'pad_shape',
                                       'scale_factor'},
                         'type': 'Collect'}],
           'type': 'OTXClsDataset'},
 'train_dataloader': {'samples_per_gpu': 8, 'workers_per_gpu': 2},
 'val': {'domain': <Domain.CLASSIFICATION: 2>,
         'empty_label': None,
         'labels': None,
         'pipeline': [{'size': 224, 'type': 'Resize'},
                      {'mean': [123.675, 116.28, 103.53],
                       'std': [58.395, 57.12, 57.375],
                       'to_rgb': False,
                       'type': 'Normalize'},
                      {'keys': ['img'], 'type': 'ImageToTensor'},
                      {'keys': ['img'], 'type': 'Collect'}],
         'test_mode': True,
         'type': 'OTXClsDataset'},
 'val_dataloader': {'samples_per_gpu': 8, 'workers_per_gpu': 2}}
early_stop: {'iteration_patience': 0, 'patience': 8, 'start': 3}
custom_hooks: [{'init_callback': 'otx.algorithms.common.tasks.base_task.OnHookInitialized',
  'type': 'CancelInterfaceHook'},
 {'priority': 71,
  'time_monitor': <otx.algorithms.common.utils.callback.TrainingProgressCallback object at 0x7f42f73a4460>,
  'type': 'OTXProgressHook',
  'verbose': True},
 {'priority': 'VERY_LOW', 'type': 'MemCacheHook'},
 {'enable_adaptive_interval_hook': False,
  'enable_eval_before_run': True,
  'type': 'AdaptiveTrainSchedulingHook'},
 {'interval': 1,
  'iteration_patience': 0,
  'metric': 'accuracy',
  'patience': 8,
  'priority': 75,
  'start': 3,
  'type': 'LazyEarlyStoppingHook'},
 {'priority': 'LOWEST', 'type': 'ForceTrainModeHook'},
 {'dst_classes': ['n02086240',
                  'n02087394',
                  'n02088364',
                  'n02089973',
                  'n02093754',
                  'n02096294',
                  'n02099601',
                  'n02105641',
                  'n02111889',
                  'n02115641'],
  'efficient_mode': True,
  'model_type': 'SAMImageClassifier',
  'sampler_flag': False,
  'sampler_type': 'balanced',
  'src_classes': [],
  'type': 'TaskAdaptHook'},
 {'type': 'LoggerReplaceHook'}]
work_dir: 'outputs/imagewoof2_20_0/logs'
resume: False
early_stop_metric: 'accuracy'
distributed: False
gpu_ids: range(0, 1)
device: 'cuda'
model_task: 'classification'
load_from: 'outputs/imagewoof2_20_0/logs/best_epoch_43.pth'
------------------------------------------------------------

Results

------------------------------------------------------------
	time elapsed: '0:06:07.917307'
	score: Performance(score: 0.47671163145838635, dashboard: (3 metric groups))
	model_path: '/home/jeom/ws/otx-vit/Experiments/vit_base_32/outputs/imagewoof2_20_0/models'
